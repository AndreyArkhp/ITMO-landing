export const publicationsData = [
    {
        image: "./images/Publication/pub24.png",
        authors: "Egor Nevezhin, Nikolay Butakov, Maria Khodorchenko, Maxim Petrov, Denis Nasonov",
        text: "Online advertising is one of the most widespread ways to reach and increase a target audience for those selling products. Usually having a form of a banner, advertising engages users into visiting a corresponding webpage. Professional generation of banners requires creative and writing skills and a basic understanding of target products. The great variety of goods presented in the online market enforce professionals to spend more and more time creating new advertisements different from existing ones. In this paper, we propose a neural network-based approach for the automatic generation of online advertising using texts from given webpages as sources. The important part of the approach is training on open data available online, which allows avoiding costly procedures of manual labeling. Collected open data consist of multiple subdomains with high data heterogeneity. The subdomains belong to different topics and vary in used vocabularies, phrases, styles that lead to reduced quality in adverts generation. We try to solve the problem of identifying existed subdomains and proposing a new ensemble approach based on exploiting multiple instances of a seq2seq model. Our experimental study on a dataset in the Russian language shows that our approach can significantly improve the quality of adverts generation.",
        title: "Topic-driven Ensemble for Online Advertising Generation",
        url: "https://aclanthology.org/2020.coling-main.206/",
    },
    {
        image: "./images/Publication/pub5.png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Denis Nasonov",
        text: "In this work, we consider a problem of predicting the next state of a given area using retrospective information. The proposed concept of hierarchical context transfer (HCT) operates on several spatial levels of the input data to overcome major issues of next state prediction problems-density variability, a significant difference between consecutive states and computational complexity. The custom loss function allows assimilating contexts of spatial levels into each other to further improve prediction quality. The proposed deep learning model (HCT-CNN) allows generating precise high-resolution predictions of the target area. We evaluate our model on the use case of predicting the next state of the urban area using a large dataset for six cities-New York, Moscow, London, Tokyo, Saint Petersburg, and Vienna. Experimental results demonstrate that HCT-CNN generates low-and high-resolution predictions of better quality",
        title: "Convolutional neural networks with hierarchical context transfer for high-resolution spatiotemporal predictions",
        url: "https://dl.acm.org/doi/abs/10.1145/3423336.3429346",
    },
    {
        image: "./images/Publication/pub21.png",
        authors: "Ksenia Mukhina, Alexander Visheratin, Denis Nasonov",
        text: "One of the areas that gathers momentum is the investigation of location-based social networks (LBSNs) because the understanding of citizens’ behavior on various scales can help to improve quality of living, enhance urban management, and advance the development of smart cities. But it is widely known that the performance of algorithms for data mining and analysis heavily relies on the quality of input data. The main aim of this paper is helping LBSN researchers to perform a preliminary step of data preprocessing and thus increase the efficiency of their algorithms. To do that we propose a spatiotemporal data processing pipeline that is general enough to fit most of the problems related to working with LBSNs. The proposed pipeline includes four main stages: an identification of suspicious profiles, a background extraction, a spatial context extraction, and a fake transitions detection. Efficiency of the",
        title: "Spatiotemporal filtering pipeline for efficient social networks data processing algorithms",
        url: "https://link.springer.com/chapter/10.1007/978-3-030-50433-5_7",
    },
    {
        image: "./images/Publication/pub14.png",
        authors: "Mikhail Melnik, Ivan Dolgov, Denis A Nasonov",
        text: "Scheduling of workload in distributed computing systems is a well-known optimization proble. A workload may include single independent software packages. However, the computational process in scientific and industrial fields is often organized as composite applications or workflows which are represented by collection of interconnected computing packages that solve a common problem. We identified three common computing modes: batch, stream and iterative. The batch mode is a classic way for one-time execution of software packages with an initially specified set of input data. Stream mode corresponds to launch of a software package for further continuous processing of active data in real time. Iterative mode is a launching of a distributed application with global synchronization at each iteration. Each computing mode has its own specifics for organization of computation process. But at the moment, there are new problems that require organization of interaction between computing modes (batch, stream, iterative) and to develop optimization algorithms for this complex computations that leads to formation of heterogeneous workflows. In this work, we present a novel developed hybrid intellectual scheme for organizing and scheduling of heterogeneous workflows based on evolutionary computing and reinforcement learning methods.",
        title: "Hybrid Intellectual Scheme for Scheduling of Heterogeneous Workflows based on Evolutionary Approach and Reinforcement Learning.",
        url: "https://www.scitepress.org/Papers/2020/101128/101128.pdf",
    },
    {
        image: "./images/Publication/pub7.png",
        authors: "Alexandr Zamiralov, Maria Khodorchenko, Denis Nasonov",
        text: "Social media stores a significant amount of information which can be used for extraction of specific knowledge. A variety of topics that arise there concerns a lot of everyday life aspects, including urban-related problems. In this work, we demonstrate the way of using the texts from social media on the topic of housing and utility problems, such as litter on the streets, graffiti on a public building or noisy neighbours. Our aim is to develop an approach based on machine learning to automatically filter such citizen messages and classify them into several categories. To achieve this, we solve the classification problem with an almost unlimited number of negative categories using the One-Class approach and combine data from several resources to construct proper text embedding by combining results from the guided topic model and deep neural pretrained BERT method. Comparison with statistics taken from the official",
        title: "Detection of housing and utility problems in districts through social media texts",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050920323978",
    },
    {
        image: "./images/Publication/pub6.png",
        authors: "Mariia Koreneva, Alexander A Visheratin, Denis Nasonov",
        text: "We present a new approach to large-scale supervised heterogeneous graph classification. We decouple a large heterogeneous graph into smaller homogeneous ones. In this paper, we show that our model provides results close to the state-of-the-art model while greatly simplifying calculations and makes it possible to process complex heterogeneous graphs on a much larger scale.",
        title: "Decoupling graph convolutional networks for large-scale supervised classification",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050920324133",
    },
    {
        image: "./images/Publication/pub19.png",
        authors: "Alexander Visheratin, Alexey Struckov, Semen Yufa, Alexey Muratov, Denis Nasonov, Nikolay Butakov, Yury Kuznetsov, Michael May",
        text: "The rapid development of scientific and industrial areas, which rely on time series data processing, raises the demand for storage that would be able to process tens and hundreds of terabytes of data efficiently. And by efficiency, one should understand not only the speed of data processing operations execution but also the volume of the data stored and operational costs when deploying the storage in a production environment such as the cloud. In this paper, we propose a concept for storing and indexing numerical time series that allows creating compact data representations optimized for cloud storages and perform typical operations-uploading, extracting, sampling, statistical aggregations, and–at high speed. Our modular database that implements the proposed approach–Peregreen–can achieve a throughput of 3 million entries per second for uploading and 48 million entries per second for extraction in Amazon EC2 while having only Amazon S3 as backend storage for all the data.",
        title: "Peregreen–modular database for efficient storage of historical time series in cloud environments",
        url: "https://www.usenix.org/conference/atc20/presentation/visheratin",
    },
    {
        image: "./images/Publication/pub16.png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Denis Nasonov, Lev Manovich",
        text: "In this work, we show how social media data can be used for the improvement of touristic experience. We present an algorithm for automated touristic paths construction. Score function for location depends on three components: location's social media popularity and rating, distances of place from others in route, and location's relevance to the city unique features. Obtained walking paths were compared to real itineraries prepared by experts for city visitors. Survey results demonstrate that respondents prefer automated routes over existing routes from touristic services. We also created touristic itineraries for 11 cities that host FIFA World Cup 2018. For each city, these routes take into account their specific features related to historical and cultural background.",
        title: "Intelligent sightseeing in immensely manifold cities: Case of 2018 fifa world cup host cities",
        url: "https://dl.acm.org/doi/abs/10.1145/3356994.3365503",
    },
    {
        image: "./images/Publication/publication_User Profiles Matching for Different Social Networks Based.png",
        authors: "Timur Sokhin, Nikolay Butakov, Denis Nasonov",
        text: "It is common practice nowadays to use multiple social networks for different social roles. Although this, these networks assume differences in content type, communications and style of speech. If we intend to understand human behaviour as a key-feature for recommender systems, banking risk assessments or sociological researches, this is better to achieve using a combination of the data from different social media. In this paper, we propose a new approach for user profiles matching across social media based on publicly available users’ face photos and conduct an experimental study of its efficiency. Our approach is stable to changes in content and style for certain social media.",
        title: "User profiles matching for different social networks based on faces identification",
        url: "https://link.springer.com/chapter/10.1007/978-3-030-29859-3_47",
    },
    {
        image: "./images/Publication/pub18.png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Denis Nasonov",
        text: "Orienteering problem (OP) is a routing problem, where the aim is to generate a path through set of nodes, which would maximize total score and would not exceed the budget. In this paper, we present an extension of classic OP—Orienteering Problem with Functional Profits (OPFP), where the score of a specific point depends on its characteristics, position in the route, and other points in the route. For solving OPFP, we developed an open-source framework for solving orienteering problems, which utilizes four core components of OP in its modular architecture. Fully-written in Go programming language our framework can be extended for solving different types of tasks with different algorithms; this was demonstrated by implementation of two popular algorithms for OP solving—Ant Colony Optimization and Recursive Greedy Algorithm. Computational efficiency of the framework was shown through solving four well-known OP types: classic Orienteering Problem (OP), Orienteering Problem with Compulsory Vertices (OPCV), Orienteering Problem with Time Windows (OPTW), and Time Dependent Orienteering Problem (TDOP) along with OPFP. Experiments were conducted on a large multi-source dataset for Saint Petersburg, Russia, containing data from Instagram, TripAdvisor, Foursquare and official touristic website. Our framework is able to construct touristic paths for different OP types within few seconds using dataset with thousands of points of interest.",
        title: "Orienteering problem with functional profits for multi-source dynamic path construction",
        url: "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0213777",
    },
    {
        image: "./images/Publication/pub1.png",
        authors: "Mikhail Melnik, Denis A Nasonov, Alexey Liniov",
        text: "In the modern world, with the growth of the volume of processed data arrays, the logic of solving problems also becomes more complex. This leads more and more often to the need to use high-performance computational clusters, such as supercomputers. Created multi-agent simulation applications require not only significant resources but often perform time-consuming complex scenarios, which significantly affects the efficiency of the executed process. However, there are various mechanisms for optimizing application execution for different needs. Unfortunately, the specificity of multi-agent simulation does not allow the use of traditional and modern algorithms due to the iteratively variable workload and limitations of a system software installed on the supercomputers. In this paper, we propose a four-level scheme for organizing the symbiotic execution (co-design) of multi-agent applications on supercomputers, as well as an effective two-level algorithm for optimizing the flow of the execution of an urban mobility simulation application. The algorithm is based on evolutionary approach and machine learning techniques.",
        title: "Intellectual Execution Scheme of Iterative Computational Models based on Symbiotic Interaction with Application for Urban Mobility Modelling.",
        url: "https://www.scitepress.org/Papers/2019/83656/83656.pdf",
    },
    {
        image: "./images/Publication/publication_Urban events prediction via convolutional neural networks a….png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Denis Nasonov",
        text: "In today’s world, it is crucial to be proactive and be prepared for events which are not happening yet. Thus, there is no surprise that in the field of social media analysis the research agenda has moved from the development of event detection methods to a brand new area - event prediction models. This research field is extremely important for all sorts of applications, from natural disasters preparation and criminal activity prevention to urban management and development of smart cities. However, even the leading models have an important disadvantage: they are based on prior knowledge about events being expected. So forecasting systems based on such models are heavily limited by a list of events that can be predicted and all events of other types will be out of systems’ scope. In this work, we try to address this issue and propose a deep learning model, which is able to predict an area of the future event in the",
        title: "Urban events prediction via convolutional neural networks and Instagram data",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050919311123",
    },
    {
        image: "./images/Publication/pub9.png",
        authors: "Iskander Safiulin, Nikolay Butakov, Dmitriy Alexandrov, Denis Nasonov",
        text: "Many companies want or prefer to use chatbot systems to provide smart assistants for accompanying human specialists especially newbies with automatic consulting. Implementation of a really useful smart assistant for a specific domain requires a knowledge base for this domain, that often exists only in the form of text documentation and manuals.\n" +
            "Lacks of properly built datasets and often expensiveness in resources and time to build one from scratch to apply data-driven methods with high quality. It motivates to seek a solution that can work without such data or require only a small amount of it though having reduced quality.\n" +
            "The reformulation of the task into an information retrieval problem where the assistant responds with a piece of documentation instead of generated sentences may make the task easier but doesn’t solve the whole problem. It allows using of metrics-based methods with reduced search quality or",
        title: "Ensemble-based method of answers retrieval for domain specific questions from text-based documentation",
        url: "https://www.sciencedirect.com/science/article/pii/S187705091931110X",
    },
    {
        image: "./images/Publication/pub10.png",
        authors: "Alexey Struckov, Semen Yufa, Alexander A Visheratin, Denis Nasonov",
        text: "Time series data as its analysis and applications recently have become increasingly important in different areas and domains. Many fields of science and industry rely on storing and processing large amounts of time series - economics and finance, medicine, the Internet of Things, environmental protection, hardware monitoring, and many others. This work presents a theoretical and experimental approach to choosing an appropriate instrument.",
        title: "Evaluation of modern tools and techniques for storing time-series data",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050919310439",
    },
    {
        image: "./images/Publication/publication_Workflow scheduling using neural networks and reinforcement lear.png",
        authors: "Mikhail Melnik, Denis Nasonov",
        text: "The development of information technologies entails a nonlinear growth of both volumes of data and the complexity of data processing itself. Scheduling is one of the main components for optimizing the operation of the computing system. Currently, there are a large number of scheduling algorithms. However, even in spite of existing hybrid schemes, there remains a need for a scheduling scheme that can quickly and efficiently solve a scheduling problem on a wide range of possible states of the computing environment, including the high heterogeneity of computational models and resources, and should have an ability to self-adapt and self-learn. At present, artificial intelligence and neural networks are the most popular methods for working with data and solving a wide range of problems, but they are not developed enough to solve the scheduling problem. Therefore, in this paper we propose a scheduling scheme",
        title: "Workflow scheduling using neural networks and reinforcement learning",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050919310440",
    },
    {
        image: "./images/Publication/publication_uilding City-Scale Walking Itineraries Using Large Geospatia.png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Denis Nasonov",
        text: "Nowadays, social networks play an important role in many aspects of people's life and in traveling in particular. People share their experience and opinions not only on specialized sites, like TripAdvisor, but also in social networks, e.g. Instagram. Combining information from different sources we can get a manifold dataset, which covers main sights, famous buildings as well as places popular with city residents. In this paper, we propose method for generation of walking tours based on large multi-source dataset. In order to create this dataset, we developed data crawling framework, which is able to collect data from Instagram at high speed. We provide several use cases for the developed itinerary generation method and demonstrate that it can significantly enrich standard touristic paths provided by official site.",
        title: "Building City-Scale Walking Itineraries Using Large Geospatial Datasets",
        url: "https://ieeexplore.ieee.org/abstract/document/8588074/",
    },
    {
        image: "./images/Publication/pub12.png",
        authors: "Ksenia D Mukhina, Alexander A Visheratin, Gali-Ketema Mbogo, Denis Nasonov",
        text: "Active development of modern cities requires not only efficient monitoring systems but furthermore forecasting systems that can predict future state of the urban area with high accuracy. In this work we present a method for urban area prediction based on geospatial activity of users in social network. One of the most popular social networks, Instagram, was taken as a source for spatial data and two large cities with different peculiarities of online activity-New York City, USA, and Saint Petersburg, Russia - were taken as target cities. We propose three different deep learning architectures that are able to solve a target problem and show that convolutional neural network based on three-dimensional convolution layers provides the best results with accuracy of 99%.",
        title: "Forecasting of the Urban Area State Using Convolutional Neural Networks",
        url: "https://ieeexplore.ieee.org/abstract/document/8588075/",
    },
    {
        image: "./images/Publication/pub17.png",
        authors: "Alexander A Visheratin, Ksenia D Mukhina, Anastasia K Visheratina, Denis Nasonov, Alexander V Boukhanovsky",
        text: "Increasing popularity of social networks made them a viable data source for many data mining applications and event detection is no exception. Researchers aim not only to find events that happen in networks but more importantly to identify and locate events occurring in the real world. In this paper, we propose an enhanced version of quadtree-convolutional quadtree (ConvTree)-and demonstrate its advantage compared to the standard quadtree. We also introduce the algorithm for searching events of different scales using geospatial data obtained from social networks. The algorithm is based on statistical analysis of historical data, generation of ConvTrees representing the normal state of the city and anomalies evaluation for events detection. Experimental study conducted on the dataset of 60 million geotagged Instagram posts in the New York City area demonstrates that the proposed approach is able to find a",
        title: "Multiscale event detection using convolutional quadtrees and adaptive geogrids",
        url: "https://dl.acm.org/doi/abs/10.1145/3282866.3282867",
    },
    {
        image: "./images/Publication/publication_Unified domain-specific language for collecting and processing dat.png",
        authors: "Nikolay Butakov, Maxim Petrov, Ksenia Mukhina, Denis Nasonov, Sergey Kovalchuk",
        text: "Data provided by social media becomes an increasingly important analysis material for social scientists, market analysts, and other stakeholders. Diversity of interests leads to the emergence of a variety of crawling techniques and programming solutions. Nevertheless, these solutions have a lack of flexibility to satisfy requirements of different users and individual crawling scenarios, that can range from a simple query to a complex workflow containing multiple steps and requiring data from different networks to be collected. To address this problem, our paper proposes an approach based on a developed domain specific language (DSL) and architecture of distributed crawling system. The DSL has a declarative style that requires the user to define the description of needed data and based on an ontological model of social networks and the essential crawling techniques. Thus, the crawling system can be",
        title: "Unified domain-specific language for collecting and processing data of social media",
        url: "https://link.springer.com/article/10.1007/s10844-018-0508-5",
    },
    {
        image: "./images/Publication/pub23.png",
        authors: "Denis Nasonov, Nikolay Butakov, Michael Melnik, Alexandr Visheratin, Alexey Linev, Pavel Shvets, Sergey Sobolev, Ksenia Mukhina",
        text: "Today advanced research is based on complex simulations which require a lot of computational resources that usually are organized in a very complicated way from technical part of the view. It means that a scientist from physics, biology or even sociology should struggle with all technical issues on the way of building distributed multi-scale application supported by a stack of specific technologies on high-performance clusters. As the result, created applications have partly implemented logic and are extremely inefficient in execution. In this paper, we present an approach which takes away the user from the necessity to care about an efficient resolving of imbalance of computations being performed in different processes and on different scales of his application. The efficient balance of internal workload in distributed and multi-scale applications may be achieved by introducing: a special multi-level model; a",
        title: "The multi-level adaptive approach for efficient execution of multi-scale distributed applications with dynamic workload",
        url: "https://link.springer.com/chapter/10.1007/978-3-030-05807-4_58",
    },
    {
        image: "./images/Publication/pub20.png",
        authors: "Anna V Kalyuzhnaya, Nikolay O Nikitin, Nikolay Butakov, Denis Nasonov",
        text: "The current paper is devoted to a problem of deviant users’ identification in social media. For this purpose, each user of social media source should be described through a profile that aggregates open information about him/her within the special structure. Aggregated user profiles are formally described in terms of multivariate random process. The special emphasis in the paper is made on methods for identifying of users with certain on a base of few precedents and control the quality of search results. Experimental study shows the implementation of described methods for the case of commercial usage of the personal account in social media.",
        title: "Precedent-Based Approach for the Identification of Deviant Behavior in Social Media",
        url: "https://link.springer.com/chapter/10.1007/978-3-319-93713-7_84",
    },
    {
        image: "./images/Publication/pub3.png",
        authors: "Denis Nasonov, Alexander A Visheratin, Alexander Boukhanovsky",
        text: "Today Big Data occupies a crucial part of scientific research areas as well as in the business analysis of large companies. Each company tries to find the best way to make generated Big Data sets valuable and profitable. However, in most cases, companies have not enough opportunities and budget to solve this complex problem. On the other hand, there are companies (i.e., in insurance or banking) that can significantly improve their business organization by applying hidden knowledge extracted from such massive data. This situation leads to the necessity of building a platform for exchange, processing, and sale of collected Big Data sets. In this paper, we propose a distributed big data platform that implements digital data marketplace based on the blockchain mechanism for data transaction integrity.",
        title: "Blockchain-based transaction integrity in distributed big data marketplace",
        url: "https://link.springer.com/chapter/10.1007/978-3-319-93698-7_43",
    },
    {
        image: "./images/Publication/publication_Towards a scenario-based solution for extreme metocean event sim.png",
        authors: "Anna V Kalyuzhnaya, Denis Nasonov, Sergey V Ivanov, Sergey S Kosukhin, Alexander V Boukhanovsky",
        text: "Today, metocean investigations, combined with forecasts and analysis of extreme events, require new design and development approaches because of their complexity. Extreme metocean events forecasting and prevention is an urgent computing task from decision-making and for reaction point of view. In this case, urgent computing scenario is an essential part that should be included in the hazard simulation and prevention system However, existed urgent computing technological concepts does not perfectly fit all tasks in a frame of extreme metocean events simulation. Many of these tasks should be executed during the overall lifecycle of hazard prevention system that includes not only urgent scenario but research part, as well In this paper, we decompose all tasks in three groups by most significant computational aspects (taking into consideration different criteria of data processing and high-performance",
        title: "Towards a scenario-based solution for extreme metocean event simulation applying urgent computing",
        url: "https://www.sciencedirect.com/science/article/pii/S0167739X17311081",
    },
    {
        image: "./images/Publication/pub22.png",
        authors: "Anton Spivak, Andrew Razumovskiy, Denis Nasonov, Alexander Boukhanovsky, Anton Redice",
        text: "The importance of data collection, processing, and analysis is rapidly growing. Big Data technologies are in high demand in many fields, including bio-informatics, hydrometeorology, and high energy physics. One of the most popular computational paradigms used in large data processing frameworks is the MapReduce programming model. Today, majority of integrated optimization mechanisms that quickly produce simple solutions typically consider only load balancing, which is not sufficient for advanced computations. Thus, more efficient and complex approaches are required. In this paper, we suggest an improved algorithm based on categories for reorganizing data in MapReduce frameworks and using replication as well as network transfer. Moreover, we introduce an algorithm customization for urgent computations which require specific approaches in terms of execution time and reliability. We also consider",
        title: "Storage tier-aware replicative data reorganization with prioritization for efficient workload processing",
        url: "https://www.sciencedirect.com/science/article/pii/S0167739X17305502",
    },
    {
        image: "./images/Publication/pub15.png",
        authors: "Alexander A Visheratin, Mikhail Melnik, Denis Nasonov, Nikolay Butakov, Alexander V Boukhanovsky",
        text: "The development of an efficient Early Warning System (EWS) is essential for the prediction and prevention of imminent natural hazards. In addition to providing a computationally intensive infrastructure with extensive data transfer, high-execution reliability and hard-deadline satisfaction are important requirements of EWS scenario processing. This is due to the fact that EWS has a limited window of opportunity to discern if a scene shows signs of an impending natural disaster. In this paper, the scheduling component of the EWS scenario is investigated and an efficient hybrid algorithm for the urgent workflows scheduling is proposed. The developed algorithm is based on traditional heuristic and meta-heuristic approaches along with state-of-the-art cloud computing principles.",
        title: "Hybrid scheduling algorithm in early warning systems",
        url: "https://www.sciencedirect.com/science/article/pii/S0167739X1730540X",
    },
    {
        image: "./images/Publication/pub8.png",
        authors: "Sergey V Kovalchuk, Evgeniy Krotov, Pavel A Smirnov, Denis A Nasonov, Alexey N Yakovlev",
        text: "This paper presents ongoing research aimed at developing a data-driven platform for clinical decision support systems (DSSs) that require integration and processing of various data sources within a single solution. Resource management is developed within a framework of an urgent computing approach to address changing requirements defined by the incoming flow of patients with urgent diseases. This work presents DSS for support of ambulance and emergency medical service management for patients with acute coronary syndrome (ACS) as a working example with integration distributed streaming data sources as well as data storages (containing electrocardiography (ECG) data, electronic medical records (EMR), real-time monitoring of medical facilities, and schedules of hospitals within a network). This DSS has been developed in collaboration with the Federal Almazov North-West Medical Research",
        title: "Distributed data-driven platform for urgent decision making in cardiological ambulance control",
        url: "https://www.sciencedirect.com/science/article/pii/S0167739X1630348X",
    },
    {
        image: "./images/Publication/pub4.png",
        authors: "Stepan Rakitin, Alexander A Visheratin, Denis Nasonov",
        text: "To provide fault tolerance, modern distributed storage systems use specialized network topologies and consensus protocols that create high overheads. The main disadvantage of existing specialized topologies is a difficulty to implement an efficient data placement that takes into account locality of the data. In scientific problems very often it is necessary to provide the semantic proximity of the data at the nodes of the distributed system. Core drawback of modern consensus protocols is that most of them use messaging through broadcasting, which is impossible for large amounts of data and storage nodes. With more stringent requirements for a fault tolerance, e.g. requirement for resistance to Byzantine errors [1], ensuring of data localization becomes nearly impossible. The purpose of this paper is to implement a distributed consensus protocol that preserves data localization and is resistant to Byzantine errors",
        title: "Byzantine fault-tolerant and semantic-driven consensus protocol",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050918315394",
    },
    {
        image: "./images/Publication/pub2.png",
        authors: "Max Petrov, Nikolay Butakov, Denis Nasonov, Mikhail Melnik",
        text: "Nowadays, data volumes increase exceptionally, a lot of information comes from different sources, for example, from mobile phones, sensors, traffic, etc. All information from these sources can be represented as a data streams, which can grow up and fall in time in their size. In the first case, data processing requires optimization via dynamic resource allocation in order to decrease processing time, in the second case, it requires optimization related with resources deallocation because removing unnecessary resources can decrease the total cost. The question is how to identify optimal amount of resources to satisfy required processing delay under certain volume of workload? Current implementation of Apache Spark Streaming and existing models can’t give us such possibility. In this paper, we propose adaptive performance model, which can dynamically scale up and down Apache Spark Streaming platform on the",
        title: "Adaptive performance model for dynamic scaling Apache Spark Streaming",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050918315485",
    },
    {
        image: "./images/Publication/publication_Workflow scheduling using neural networks and reinforcement lear.png",
        authors: "Max Petrov, Nikolay Butakov, Denis Nasonov, Mikhail Melnik",
        text: "Nowadays, data volumes increase exceptionally, a lot of information comes from different sources, for example, from mobile phones, sensors, traffic, etc. All information from these sources can be represented as a data streams, which can grow up and fall in time in their size. In the first case, data processing requires optimization via dynamic resource allocation in order to decrease processing time, in the second case, it requires optimization related with resources deallocation because removing unnecessary resources can decrease the total cost. The question is how to identify optimal amount of resources to satisfy required processing delay under certain volume of workload? Current implementation of Apache Spark Streaming and existing models can’t give us such possibility. In this paper, we propose adaptive performance model, which can dynamically scale up and down Apache Spark Streaming platform on the",
        title: "Adaptive performance model for dynamic scaling Apache Spark Streaming",
        url: "https://www.sciencedirect.com/science/article/pii/S1877050918315485",
    },
    {
        image: "./images/Publication/pub11.png",
        authors: "Artem M Chirkin, Adam SZ Belloum, Sergey V Kovalchuk, Marc X Makkes, Mikhail A Melnik, Alexander A Visheratin, Denis A Nasonov",
        text: "Estimation of the execution time is an important part of the workflow scheduling problem. The aim of this paper is to highlight common problems in estimating the workflow execution time and propose a solution that takes into account the complexity and the stochastic aspects of the workflow components as well as their runtime. The solution proposed in this paper addresses the problems at different levels from a task to a workflow, including the error measurement and the theory behind the estimation algorithm. The proposed makespan estimation algorithm can be integrated easily into a wide class of schedulers as a separate module. We use a dual stochastic representation, characteristic/distribution function, in order to combine task estimates into the overall workflow makespan. Additionally, we propose the workflow reductions—operations on a workflow graph that do not decrease the accuracy of the estimates",
        title: "Execution time estimation for workflow scheduling",
        url: "https://www.sciencedirect.com/science/article/pii/S0167739X17300304",
    }
]